{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TklcmGHfIPY0",
        "4eT7kzkEIalN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes Classifier\n",
        "## CS 72 Final Project\n",
        "### John Guerrerio\n",
        "### john.j.guerrerio.26@dartmouth.edu\n",
        "\n",
        "This notebook contains the code to fine-tune a naive bayes for the Inbox Guardian classification task using both bad-of-words and Tf-Idf features.  We use a dataset of the most recent 500 email chains we recieved - see the write up for details.  "
      ],
      "metadata": {
        "id": "jSqhXF_BYqMP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1C1GYFP6Gop"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# functions to convert numerical labels to class names - helps with error analysis outputs\n",
        "def interpretBinaryLabel(x):\n",
        "  if x == 1:\n",
        "    return \"relevant\"\n",
        "  else:\n",
        "    return \"irrelevant\"\n",
        "\n",
        "def interpretTrinaryLabel(x):\n",
        "  if x == 0:\n",
        "    return \"irrelevant\"\n",
        "  elif x == 1:\n",
        "    return \"normal\"\n",
        "  else:\n",
        "    return \"urgent\""
      ],
      "metadata": {
        "id": "cgGfJNW3Gyp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 42 # random seed to ensure results are reproducible\n",
        "META = False # True if we only want to show the model senders and subjects, false if we want to pass in email body as well"
      ],
      "metadata": {
        "id": "TNIr9FJN6eHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('fullDataset.csv')\n",
        "# Shuffles the dataset, as it was ordered by label during construction\n",
        "df = df.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "WG7vhiGA6m5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define our docs based on the META flag\n",
        "if META:\n",
        "  docs = df[\"Meta\"].tolist()\n",
        "else:\n",
        "  docs = df[\"Full\"].tolist()\n",
        "\n",
        "labels = df[\"Label\"].tolist()\n",
        "\n",
        "print(len(docs))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "id": "QTIuw76060W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Naive Bayes\n",
        "## Bag of Words vectors\n",
        "## Three Classes"
      ],
      "metadata": {
        "id": "TklcmGHfIPY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate BOW vectors for each document\n",
        "# the vectorizer strips accents, lowercases, removes stopwords, and only considers the most frequent 7500 words\n",
        "vectorizer = CountVectorizer(strip_accents='unicode', lowercase = True, stop_words='english', max_features=7500)\n",
        "processed = vectorizer.fit_transform(docs)"
      ],
      "metadata": {
        "id": "SbGXq_hm66wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.vocabulary_)"
      ],
      "metadata": {
        "id": "_xTl8GbkCPsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docTermMatrix = processed.toarray()\n",
        "\n",
        "# generate train, test sets\n",
        "train, test, trainLabels, testLabels = train_test_split(docTermMatrix, labels, test_size=0.2, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "FruBIv-e-Brh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train))\n",
        "print(len(trainLabels))\n",
        "\n",
        "print(len(test))\n",
        "print(len(testLabels))"
      ],
      "metadata": {
        "id": "mNNZWnsO-2Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MultinomialNB(alpha = 1.0) # add one smoothing\n",
        "\n",
        "# train the classifier\n",
        "classifier.fit(train, trainLabels)"
      ],
      "metadata": {
        "id": "HHc4CVDy_DhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate classifier on the test set\n",
        "predictions = classifier.predict(test)\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "metadata": {
        "id": "xNcDhjHa_prX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(testLabels, predictions))"
      ],
      "metadata": {
        "id": "RKA-SezkAVdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Naive Bayes\n",
        "## BOW\n",
        "## Two Classes"
      ],
      "metadata": {
        "id": "4eT7kzkEIalN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converts all \"urgent\" labels to \"relevant\"\n",
        "# Allows us to collpase the trinary classification task into a relevant/irrelevant binary classification task\n",
        "def changeLabels(x):\n",
        "  if x == 2:\n",
        "    return 1\n",
        "  else:\n",
        "    return x\n",
        "\n",
        "# convert trinary labels to binary\n",
        "new_labels = df['Label'].apply(changeLabels).tolist()\n",
        "print(new_labels)"
      ],
      "metadata": {
        "id": "RW2hRSO9IduP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate train, test sets\n",
        "train, test, trainLabels, testLabels = train_test_split(docTermMatrix, new_labels, test_size=0.2, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "B66DpjlvIpJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MultinomialNB(alpha = 1.0) # add one smoothing\n",
        "\n",
        "# train the naive bayes classifier\n",
        "classifier.fit(train, trainLabels)"
      ],
      "metadata": {
        "id": "YvoOyTTMI-Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the classifier on the test set\n",
        "predictions = classifier.predict(test)\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "metadata": {
        "id": "dZ2AgtrPJB6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(testLabels, predictions))"
      ],
      "metadata": {
        "id": "ZNXco8euJG1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Naive Bayes\n",
        "## Tf-IDF\n",
        "## Three Classes"
      ],
      "metadata": {
        "id": "HR5Stk6XH_JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tf-Idf vectorizer - converts docs to tf-idf vectors\n",
        "# the vectorizer strips accents, lowercases, removes stopwords, and only considers the most frequent 7500 words\n",
        "tfidfVectorizer = TfidfVectorizer(strip_accents='unicode', lowercase = True, stop_words='english', max_features=7500)\n",
        "processed = tfidfVectorizer.fit_transform(docs)"
      ],
      "metadata": {
        "id": "RBOKNxPwBtDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tfidfVectorizer.vocabulary_)"
      ],
      "metadata": {
        "id": "I3BpQooXCo9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docTermMatrix = processed.toarray()\n",
        "\n",
        "# generate train, test sets for tf-idf features\n",
        "train, test, trainLabels, testLabels = train_test_split(docTermMatrix, labels, test_size=0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "# copy of train/test sets with document text (as opposed to tf-idf vectors) for error analysis - random state ensures the data is split the same way every time\n",
        "trainText, testText, _, _ = train_test_split(docs, labels, test_size=0.2, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "DAC3W1aZCy-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train))\n",
        "print(len(trainLabels))\n",
        "\n",
        "print(len(test))\n",
        "print(len(testLabels))"
      ],
      "metadata": {
        "id": "r76NIt4dC5mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MultinomialNB(alpha = 0.1) # add 0.1 smoothing\n",
        "\n",
        "# train the classifier\n",
        "classifier.fit(train, trainLabels)"
      ],
      "metadata": {
        "id": "rrir1LG5DAee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the classifier on the test set\n",
        "predictions = classifier.predict(test)\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "metadata": {
        "id": "A0ZBeVViDHfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(testLabels, predictions))"
      ],
      "metadata": {
        "id": "AIRW9JqJDPtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we perform error analysis on the if-idf naive bayes models as they are the best perfoming model across all the expiriments we ran\n",
        "# see the write-up for details\n",
        "\n",
        "# print the text, predicted label, and actual label of all misclassified dcuments\n",
        "for i in range(len(predictions)):\n",
        "  if predictions[i] != testLabels[i]:\n",
        "    print(\"Email: \" + str(testText[i]))\n",
        "    print(\"Predicted Label: \" + interpretTrinaryLabel(predictions[i]))\n",
        "    print(\"Actual Label: \" + interpretTrinaryLabel(testLabels[i]))\n",
        "    print()"
      ],
      "metadata": {
        "id": "p3K1ZwrEHZV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Naive Bayes\n",
        "## Tf-IDF\n",
        "## Two Classes"
      ],
      "metadata": {
        "id": "q0f0PXwOHvQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tf-Idf vectorizer - converts docs to tf-idf vectors\n",
        "# the vectorizer strips accents, lowercases, removes stopwords, and only considers the most frequent 7500 words\n",
        "tfidfVectorizer = TfidfVectorizer(strip_accents='unicode', lowercase = True, stop_words='english', max_features=7500)\n",
        "processed = tfidfVectorizer.fit_transform(docs)\n",
        "docTermMatrix = processed.toarray()\n",
        "\n",
        "# generate train, test sets for tf-idf features\n",
        "train, test, trainLabels, testLabels = train_test_split(docTermMatrix, new_labels, test_size=0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "# copy of train/test sets with document text (as opposed to tf-idf vectors) for error analysis - random state ensures the data is split the same way every time\n",
        "trainText, testText, _, _ = train_test_split(docs, new_labels, test_size=0.2, random_state=RANDOM_STATE) # copy we can read the text of for error analysis - random state ensures the data is split the same way every time"
      ],
      "metadata": {
        "id": "5L5-L7wUENZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train))\n",
        "print(len(trainLabels))\n",
        "\n",
        "print(len(test))\n",
        "print(len(testLabels))"
      ],
      "metadata": {
        "id": "uxPvVI90EbPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MultinomialNB(alpha = 0.1) # add 0.1 smoothing\n",
        "\n",
        "# train the classifier\n",
        "classifier.fit(train, trainLabels)"
      ],
      "metadata": {
        "id": "rx0MQDXsE0HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the classifier on the test set\n",
        "predictions = classifier.predict(test)\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "metadata": {
        "id": "cYpDoNJWFMBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(testLabels, predictions))"
      ],
      "metadata": {
        "id": "m9Yru2JqGZkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we perform error analysis on the if-idf naive bayes models as they are the best perfoming model across all the expiriments we ran\n",
        "# see the write-up for details\n",
        "\n",
        "# print the text, predicted label, and actual label of all misclassified dcuments\n",
        "for i in range(len(predictions)):\n",
        "  if predictions[i] != testLabels[i]:\n",
        "    print(\"Email: \" + str(testText[i]))\n",
        "    print(\"Predicted Label: \" + interpretBinaryLabel(predictions[i]))\n",
        "    print(\"Actual Label: \" + interpretBinaryLabel(testLabels[i]))\n",
        "    print()"
      ],
      "metadata": {
        "id": "dRFKlgM6G01O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}