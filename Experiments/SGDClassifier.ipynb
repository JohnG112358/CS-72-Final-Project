{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Gradient Descent Classifier\n",
        "## CS 72 Final Project\n",
        "### John Guerrerio\n",
        "### john.j.guerrerio.26@dartmouth.edu\n",
        "\n",
        "This notebook contains the code to fine-tune a logistic regression classifier and a support vector machine for the Inbox Guardian classification task.  We use a dataset of the most recent 500 email chains we recieved - see the write up for details.  "
      ],
      "metadata": {
        "id": "Ppo7ZTgBVtMz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laFLcHSDMTO1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 42 # random seed to ensure results are reproducible\n",
        "META = False # True if we only want to show the model senders and subjects, false if we want to pass in email body as well\n",
        "THREE_CLASSES = False # True for trinary classification task, false for binary"
      ],
      "metadata": {
        "id": "IG7pWuNEMZHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('fullDataset.csv')\n",
        "# Shuffles the dataset, as it was ordered by label during construction\n",
        "df = df.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "VbJm6jOWMbfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converts all \"urgent\" labels to \"relevant\"\n",
        "# Allows us to collpase the trinary classification task into a relevant/irrelevant binary classification task\n",
        "def changeLabels(x):\n",
        "  if x == 2:\n",
        "    return 1\n",
        "  else:\n",
        "    return x"
      ],
      "metadata": {
        "id": "_guttrFUMhfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define our docs based on the META flag\n",
        "if META:\n",
        "  docs = df[\"Meta\"].tolist()\n",
        "else:\n",
        "  docs = df[\"Full\"].tolist()\n",
        "\n",
        "# define our labels based on the THREE_CLASSES flags\n",
        "if THREE_CLASSES:\n",
        "  labels = df[\"Label\"].tolist()\n",
        "else:\n",
        "  labels = df['Label'].apply(changeLabels).tolist()\n",
        "\n",
        "print(len(docs))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "id": "9uQfYBGpMxPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "## Tf-idf"
      ],
      "metadata": {
        "id": "EjlNDkUwNZz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert all documents to Tf-Idf vectors\n",
        "tfidfVectorizer = TfidfVectorizer(strip_accents='unicode', lowercase = True, stop_words='english', max_features=7500)\n",
        "processed = tfidfVectorizer.fit_transform(docs)\n",
        "docTermMatrix = processed.toarray()"
      ],
      "metadata": {
        "id": "t_03AMuGM8hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate train, test, validation sets\n",
        "train, validAndTest, trainLabels, validAndTestLabels = train_test_split(docTermMatrix, labels, test_size=0.3, random_state=RANDOM_STATE)\n",
        "valid, test, validLabels, testLabels = train_test_split(validAndTest, validAndTestLabels, test_size=0.5, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "tOXRCyH8Noq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of possible values for hyperparameters - we will grid search across all of these values\n",
        "LR_PENALTY = [\"l2\", \"l1\", \"elasticnet\"] # determines the penalty term\n",
        "LR_ALPHA = [0.01, 0.001, 0.0002, 0.0001, 0.0005, 0.00001] # determines the learning rate\n",
        "LR_EPOCHS = [500, 750, 1000, 1250, 1500] # number of epochs for training\n",
        "\n",
        "# sklearn paritions its own validation set from the train data we pass in an and stops training once performance on\n",
        "# its validation set no longer improves after 5 epochs\n",
        "# this early stopping is important to prevent overfitting\n",
        "EARLY_STOPPING = True\n",
        "VALIDATION_FRACTION = 0.15 # fraction of training data to use for validation"
      ],
      "metadata": {
        "id": "ImJKuwpvNO4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We grid search to optimize macro-averaged F1 on the validation set\n",
        "\n",
        "# Best validation f1/hyperparameters we've seen so far\n",
        "lr_bestPenalty = \"\"\n",
        "lr_bestAplha = 0\n",
        "lr_bestEpochs = 0\n",
        "lr_bestF1 = 0\n",
        "\n",
        " # grid search\n",
        "for penalty in LR_PENALTY:\n",
        "  for alpha in LR_ALPHA:\n",
        "    for epoch in LR_EPOCHS:\n",
        "      # we specify log_loss to train a logistic regression classifier (see sklearn documentation)\n",
        "      LogReg = SGDClassifier(loss = 'log_loss', penalty=penalty, alpha=alpha, max_iter=epoch, early_stopping=EARLY_STOPPING, validation_fraction=VALIDATION_FRACTION, random_state=RANDOM_STATE)\n",
        "      LogReg.fit(train, trainLabels)\n",
        "\n",
        "      # evaluation on the validation set\n",
        "      predictions = LogReg.predict(valid)\n",
        "      f1 = f1_score(validLabels, predictions, average=\"macro\")\n",
        "\n",
        "      # if we get a better validation f1, update the best f1/hyperparameters we've seen\n",
        "      if f1 > lr_bestF1:\n",
        "        lr_bestF1 = f1\n",
        "        lr_bestPenalty = penalty\n",
        "        lr_bestAplha = alpha\n",
        "        lr_bestEpochs = epoch\n",
        "\n",
        "# best performing hyperparameters\n",
        "print(\"Best f1: \" + str(lr_bestF1))\n",
        "print(\"Best epochs: \" + str(lr_bestEpochs))\n",
        "print(\"Best alpha: \" + str(lr_bestAplha))\n",
        "print(\"Best penalty: \" + str(lr_bestPenalty))"
      ],
      "metadata": {
        "id": "06htkCQdN0hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train a logistic regression classifier with the best-performing hyperparameters\n",
        "LogReg = SGDClassifier(loss = 'log_loss', penalty=lr_bestPenalty, alpha=lr_bestAplha, max_iter=lr_bestEpochs, early_stopping=EARLY_STOPPING, validation_fraction=VALIDATION_FRACTION, random_state=RANDOM_STATE)\n",
        "LogReg.fit(train, trainLabels)\n",
        "predictions = LogReg.predict(test)"
      ],
      "metadata": {
        "id": "0jY00RMDOq3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate logistic regression classifier on the test set\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "metadata": {
        "id": "j8LgX5GiOshs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(testLabels, predictions))"
      ],
      "metadata": {
        "id": "w_FAFFP-XwpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM\n",
        "## Tf-Idf"
      ],
      "metadata": {
        "id": "Q7qOWqIaPhDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of possible values for hyperparameters - we will grid search across all of these values\n",
        "PENALTY = [\"l2\", \"l1\", \"elasticnet\"] # determines the penalty term\n",
        "ALPHA = [0.01, 0.001, 0.0002, 0.0001, 0.0005, 0.00001] # determines the learning rate\n",
        "EPOCHS = [500, 750, 1000, 1250, 1500] # number of epochs for training\n",
        "\n",
        "# sklearn paritions its own validation set from the train data we pass in an and stops training once performance on\n",
        "# its validation set no longer improves after 5 epochs\n",
        "# this early stopping is important to prevent overfitting\n",
        "EARLY_STOPPING = True\n",
        "VALIDATION_FRACTION = 0.15 # fraction of training data to use for validation"
      ],
      "metadata": {
        "id": "5GvytQHNPrjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We grid search to optimize macro-averaged F1 on the validation set\n",
        "\n",
        "# Best validation f1/hyperparameters we've seen so far\n",
        "bestPenalty = \"l2\"\n",
        "bestAplha = 0.0001\n",
        "bestEpochs = 1000\n",
        "bestF1 = 0\n",
        "\n",
        "# grid search\n",
        "for penalty in PENALTY:\n",
        "  for alpha in ALPHA:\n",
        "    for epoch in EPOCHS:\n",
        "      # the default loss function for SGDClassifier generates an SVM (see sklearn documentation)\n",
        "      SVM = SGDClassifier(penalty=penalty, alpha=alpha, max_iter=epoch, early_stopping=EARLY_STOPPING, validation_fraction=VALIDATION_FRACTION, random_state=RANDOM_STATE)\n",
        "      SVM.fit(train, trainLabels)\n",
        "\n",
        "      # evalaute on validation set\n",
        "      predictions = SVM.predict(valid)\n",
        "      f1 = f1_score(validLabels, predictions, average=\"macro\")\n",
        "\n",
        "      # if we get a better validation f1, update the best f1/hyperparameters we've seen\n",
        "      if f1 > bestF1:\n",
        "        bestF1 = f1\n",
        "        bestPenalty = penalty\n",
        "        bestAplha = alpha\n",
        "        bestEpochs = epoch\n",
        "\n",
        "# best performing hyperparameters\n",
        "print(\"Best f1: \" + str(bestF1))\n",
        "print(\"Best epochs: \" + str(bestEpochs))\n",
        "print(\"Best alpha: \" + str(bestAplha))\n",
        "print(\"Best penalty: \" + str(bestPenalty))"
      ],
      "metadata": {
        "id": "ARD_Rd1uPtHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train a SVM with the best-performing hyperparameters\n",
        "SVM = SGDClassifier(penalty=bestPenalty, alpha=bestAplha, max_iter=bestEpochs, early_stopping=EARLY_STOPPING, validation_fraction=VALIDATION_FRACTION, random_state=RANDOM_STATE) # this is a linear SVM\n",
        "SVM.fit(train, trainLabels)\n",
        "predictions = SVM.predict(test)"
      ],
      "metadata": {
        "id": "W5ZvoEHWPvgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation the SVM on the test set\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "metadata": {
        "id": "SRtlXcsCPx1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(testLabels, predictions))"
      ],
      "metadata": {
        "id": "ZyWKKcfrYUpR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}